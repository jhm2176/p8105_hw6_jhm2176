---
title: "Homework 6"
author: "Jenesis Merriman"
date: "December 3, 2022"
output: github_document
---

```{r setup, include=FALSE} 
library(tidyverse) #used
library(broom) #used
library(readr) #used
library(mgcv) #used
library(modelr) #used

library(viridis) #used

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

This problem uses 2017 Central Park weather data and solutions from the course website.

### Data

The code chunk below will download the data:

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

### Bootstrapping

To obtain a distribution for $\hat{r}^2$, we will draw bootstrap samples, apply a model to each, extract the value of initerest, and summarize. Here, we'll use `modelr::bootstrap` to draw the samples and `glance` to produce `r.squared` values. 

```{r}
weather_df %>% 
  bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, glance)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  ggplot(aes(x = r.squared)) + geom_density()
```

In this example, the $\hat{r}^2$ value is high, and the upper bound at 1 may be a cause for the generally skewed shape of the distribution. If we wanted to construct a confidence interval for $R^2$, we could take the 2.5% and 97.5% quantiles of the estimates across bootstrap samples. However, because the shape isn't symmetric, using the mean +/- 1.96 times the standard error probably wouldn't work well.

We can produce a distribution for $\log(\beta_0 * \beta1)$ using a similar approach, with a bit more wrangling before we make our plot.

```{r}
weather_df %>% 
  bootstrap(n = 1000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models) %>% 
  unnest(results) %>% 
  select(id = `.id`, term, estimate) %>% 
  pivot_wider(
    names_from = term, 
    values_from = estimate) %>% 
  rename(beta0 = `(Intercept)`, beta1 = tmin) %>% 
  mutate(log_b0b1 = log(beta0 * beta1)) %>% 
  ggplot(aes(x = log_b0b1)) + geom_density()
```

As with  $\hat{r}^2$, this distribution is somewhat skewed and has some outliers. 

## Problem 2

This problem uses data gathered by the Washington Post on homicides in 50 large U.S. cities.

### Data

First, I will load and tidy the data. 

The following code uses `mutate` to update variables to appropriate types, convert reported_date into a more readable format (YYY-MM-DD), and correct the capitalization of victim_first and victim_last. It also creates two new variables: i) a `city_state` variable that returns both city and state (e.g. “Baltimore, MD”), and ii) a binary variable `solved` indicating whether the homicide is solved (TRUE) or not (FALSE). Solved homicides are defined as homicides for which the disposition is "Closed by arrest." `filter` is used to omit homicides in Dallas, TX; Phoenix, AZ; Kansas City, MO; and Tulsa, AL, and to limit our analysis to homicides for which victim_race is white or Black.

```{r}
homicides =
  read_csv("./data/homicide-data.csv") %>% #load data
  janitor::clean_names() %>% #clean names
  mutate(city_state = as.factor(str_c(city, state, sep = ", ")), #new variable
         solved = as.logical(ifelse(disposition %in% c("Closed by arrest"), TRUE, FALSE)), #new variable
         reported_date = as.Date(as.character(reported_date),"%Y%m%d"), #fixes date format
         victim_age = as.numeric(victim_age), #character to double
         victim_first = str_to_title(victim_first), #fixes all caps
         victim_last = str_to_title(victim_last), #fixes all caps
         victim_sex = as.factor(victim_sex), #character to factor
         victim_race = as.factor(victim_race), #character to factor
         city = as.factor(city), #character to factor
         state = as.factor(state)) %>% #character to factor
  filter(city_state != "Dallas, TX" & city_state != "Phoenix, AZ" & city_state != "Kansas City, MO" & city_state != "Tulsa, AL") %>%
  filter(victim_race == "White" | victim_race == "Black")
```
### Model

Next, I will use the `glm` function to fit a logistic regression with solved vs unsolved as the outcome and victim age, sex and race as predictors for the city of Baltimore, MD.

```{r}
baltimore =
  homicides %>%
  filter(city_state == "Baltimore, MD")

fit = glm(solved ~ victim_age + victim_sex + victim_race, data = baltimore, family = "binomial")
```

The following code saves the output of my logistic regression model as an R object. `tidy` and `filter` are used to obtain the adjusted odds ratio estimate and confidence interval for solving homicides comparing male victims to female victims, keeping all other variables fixed.

```{r}
fit_output =
  fit %>% 
  tidy(exponentiate = TRUE, conf.int = TRUE, conf.level = 0.95) %>%
  filter(term == "victim_sexMale") %>%
  select(term, "adjusted_OR" = "estimate", "CI_lower" = "conf.low", "CI_upper" = "conf.high")

fit_output
```

Now, I will run `glm` for each of the cities in the homicides dataset, and extract the adjusted odds ratio and confidence interval for solving homicides comparing male victims to female victims. The following "tidy" pipeline uses `purrr::map`, `glm`, `tidy`, list columns, and `unnest` to create a dataframe with estimated ORs and CIs for each city. `filter` and `select` are used to select our values of interest.

```{r}
city_glm =
  homicides %>% 
  nest(data = -city_state) %>% 
  mutate(
    models = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race, family = "binomial", data = .x)),
    exp_results = map(models, tidy, exponentiate = TRUE, conf.int = TRUE, conf.level = 0.95)) %>%
  select(-data, -models) %>% 
  unnest(exp_results) %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, 
         term, 
         "adjusted_OR" = "estimate", 
         "CI_lower" = "conf.low",
         "CI_upper" = "conf.high")
city_glm
```
### Adjusted OR Plot

Finally, the following code uses `geom_point` and `geom_errorbar` to create a plot showing the estimated adjusted odds ratios and confidence intervals for each city. Cities are arranged in ascending order of estimated OR.

```{r}
city_glm %>%
  ggplot(aes(x = reorder(city_state, +adjusted_OR), y = adjusted_OR)) +
  geom_point(show.legend = FALSE) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(
    title = "Adjusted OR for homicide resolution comparing male victims to female victims",
    x = "City",
    y = "Adjusted OR")
```
 
 **Comment:** The plot suggests that the odds of homicide resolution for male victims is less than the odds of homicide resolution for female victims in most of our analyzed cities, in general, after adjusting for victim age and race. In other words, after adjusting for victim age and race, homicides are generally more likely to be solved in cases where the victim is a woman compared to cases where the victim is a man. This is true for all cities in our dataset *except* Atlanta, GA; Richmond, VA; Nashville, TN; Fresno, CA; Stockton, CA; and Albuquerque, NM, where the adjusted OR >= 1, indicating that the odds of homicide resolution for male victims is equal to or greater than the odds of homicide resolution for female victims in these cities.

## Problem 3

This problem uses data gathered to understand the effects of several variables on a child’s birthweight. This dataset includes information on roughly 4000 children.

### Data

First, I will load and clean the data for regression analysis. `mutate` is used to convert babysex, frace, malform, and mrace from numeric variables to factor variables. `is.na` and `unique` are used to check for missing and unusual data. 

```{r results='hide'}
birthweight =
  read_csv("./data/birthweight.csv") %>% #load data
  janitor::clean_names() %>%
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         malform = as.factor(malform),
         mrace = as.factor(mrace))

colSums(is.na(birthweight)) #check for missing data: none missing
lapply(birthweight, unique) #check for unusual values: menarche = 0, 1 observation
```

No missing data was identified. There is one observation where menarche = 0, which is unexpected, because our menarche variable represents the mother’s age at menarche (years). I will make note of this but refrain from changing the data.

### Model

Next, I will fit a regression model for birthweight using `step` and `lm` to preform the stepwise model selection procedure by AIC.

```{r fit model}
fit_step = step(lm(bwt ~ ., birthweight), direction = "both", trace = FALSE)

tidy(fit_step)
```
This model was selected using stepwise selection by AIC, a data-driven model-building process. Stepwise selection is a combination of forward and backwards model selection, during which variables are removed from and entered into the model in a way that leads to the best improvement in AIC (smallest AIC). The resulting model is `r format(formula(fit_step))`.

### Residuals vs Fits Plot

The following code uses `add_predictions` and `add_residuals` to create a plot of model residuals against fitted values.

```{r residuals plot}
birthweight %>%
  add_residuals(fit_step) %>%
  add_predictions(fit_step) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() +
  geom_hline(yintercept = 0,linetype = "dashed")

#plot(fit_step) used to verify
```
**Comment:** This residuals vs fits plot has some issues. An ideal residuals vs fits plot would show a random scatter of points that form a rough horizontal band around the residual=0 line, with no outliers/stand out points. Instead, this plot inidicates the presence of outliers and a clustering of points where pred is between 2500 and 3500. For the purpose of this assignment, I will note these issues and move on.

### Model Comparison

Finally, I will compare my selected fit_step model to two other models:

* fit_i using length at birth and gestational age as predictors
* fit_ii using head circumference, length, sex, and all interactions between these as predictors

```{r comparison models}
fit_i = lm(bwt ~ blength + gaweeks, data = birthweight)
fit_ii = lm(bwt ~ bhead + blength + babysex + bhead * blength * babysex, data = birthweight)

tidy(fit_i)
tidy(fit_ii)
```

The following code uses `crossv_mc`, `mutate`, and `map` functions in `purrr` to compare the cross-validated prediction errors of fit_step, fit_i, and fit_ii. It does so by generating training and testing datasets, fitting the three models to assess prediction accuracy, and obtaining RMSEs for each model.

```{r}
cv_df = 
  crossv_mc(birthweight, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
  )

cv_df = 
  cv_df %>% 
  mutate(
    step_fits = map(.x = train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
                gaweeks + mheight + mrace + parity + ppwt + smoken, data = .x)),
    i_fits =  map(.x = train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    ii_fits = map(.x = train, ~lm(bwt ~ bhead + blength + babysex + bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_step = map2_dbl(.x = step_fits, .y = test, ~rmse(model = .x, data = .y)),
    rmse_i =    map2_dbl(.x = i_fits,    .y = test, ~rmse(model = .x, data = .y)),
    rmse_ii = map2_dbl(.x = ii_fits, .y = test, ~rmse(model = .x, data = .y))
  )
```

The following code creates a plot showing the distribution of RMSE values for each model:

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_boxplot()
```

**Comment:** Based on this plot, the fit_step model is the best fit for our data. Compared to the other two models, fit_step has the lowest RMSE values, on average.